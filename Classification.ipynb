{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOip4mvr04h/AjPH3HlI8xy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felstuff/BackToBasic/blob/master/Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi1NDyOj8XjQ",
        "colab_type": "text"
      },
      "source": [
        "from youtube video: https://www.youtube.com/watch?v=Q93dTTR3sHM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSDKelaJ9S5y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62e9d43c-267b-468e-8898-26ac55c0bbca"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset =  pd.read_csv(\"cancer.csv\")\n",
        "print(len(dataset.columns)) \n",
        "#this is formula helps you count the number columns there is on the csv file"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD3jLRhC-nNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = dataset.iloc[:, 2:29].values\n",
        "y = dataset.iloc[:, 1].values \n",
        "# values all the figures from the data without the header, and basically converting all\n",
        "# the data into something that the machine can read"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meO010IZMm4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2) \n",
        "#always remember this code if you wanna run test split"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2N0AkuUR6Sd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import  StandardScaler\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.fit_transform(x_test)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7mRlUebOUQH",
        "colab_type": "text"
      },
      "source": [
        "#this is logistic regression part, and is actually a classification algorithm\n",
        "#will need the logistic regression model becuase cancer prediction either \"yes\" OR \"no\", hence you need something like a S shape model becuase it takes into account that anything that's in btw the yess & nos \n",
        "#whereas liner regression works like a sliding scale "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3-XzEzd8WvN",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsNoC2ULORk7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "818fc0bf-6645-4de8-ee42-d99d73858acc"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logistic_classifier = LogisticRegression()\n",
        "#the () are left empty becuase the paraments are not set, AKA the list of codes below\n",
        "logistic_classifier.fit(x_train, y_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99MITsSyTfM4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d01efee2-ebef-4319-eea5-d76e990cae41"
      },
      "source": [
        "y_preds = logistic_classifier.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#to see how accurate the model is, shows you the mis-classification, and tells you how many of them are classifed wrongly  \n",
        "#shows you the mis-classification\n",
        "print(confusion_matrix(y_test, y_preds))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[76  0]\n",
            " [ 0 38]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVudiNUNX9am",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f8832a91-61fa-44b1-c9f9-b28134d297eb"
      },
      "source": [
        "from sklearn.svm import SVC \n",
        "\n",
        "svm = SVC(kernel=\"rbf\") \n",
        "svm.fit(x_train, y_train)\n",
        "\n",
        "# svm = support vector machine  \n",
        "#\"kernel\" reference need to see from youtube video"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6aQuqyJbDKW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c0e10884-af5c-4776-ca80-9a3fc0398121"
      },
      "source": [
        "y_preds = svm.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(confusion_matrix(y_test, y_preds))\n",
        "\n",
        "#SVM actually better than logoistic regression"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[76  0]\n",
            " [ 1 37]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}